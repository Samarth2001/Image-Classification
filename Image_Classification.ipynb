{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cv3K3oaksJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80a7ceb-e3a7-4c4f-82d7-ca810131d612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 39.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 43.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 45.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 55 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 53.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 60.1 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "2ZLHmLUKqPOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571ddf01-c426-4e8a-d88a-c8d14b72f330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jz5x0JoskPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f824ba64-99bd-4cab-d97a-319e74392151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ImageClassificationEIS/\n"
          ]
        }
      ],
      "source": [
        "image_path = \"/content/gdrive/MyDrive/ImageClassificationEIS/\"\n",
        "#image_path = os.path.join(os.path.dirname(image_path), 'data')\n",
        "print(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_fOlZsklmlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0febc2e2-5a8f-4f5a-fcd5-b365750df007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Load image with size: 5015, num_label: 5, labels: road, shop, sign, trafficsignal, tvmonitor.\n",
            "<tensorflow_examples.lite.model_maker.core.data_util.image_dataloader.ImageClassifierDataLoader object at 0x7f1e701a6fd0>\n"
          ]
        }
      ],
      "source": [
        "data = DataLoader.from_folder(image_path)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY4UU5SUobtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7362d80-70e9-4e47-9dd0-6e10e785811d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow_examples.lite.model_maker.core.data_util.image_dataloader.ImageClassifierDataLoader object at 0x7f1e7cd547d0> <tensorflow_examples.lite.model_maker.core.data_util.image_dataloader.ImageClassifierDataLoader object at 0x7f1e7024cbd0>\n"
          ]
        }
      ],
      "source": [
        "train_data, rest_data = data.split(0.9)\n",
        "val_data, test_data = rest_data.split(0.5)\n",
        "print(train_data,val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih4Wx44I482b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "  plt.xlabel(data.index_to_label[label.numpy()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inception_v4_spec = image_classifier.ModelSpec(\n",
        "    uri='https://tfhub.dev/google/imagenet/inception_v4/feature_vector/1')\n",
        "inception_v4_spec.input_image_shape = [299, 299]"
      ],
      "metadata": {
        "id": "-a00Qq0fxeor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvYSUuJY3QxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb08408-f439-4f98-92fd-24d32a2ba143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2_1 (Hub  (None, 2048)             21802784  \n",
            " KerasLayerV1V2)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 10245     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,813,029\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 1016s 7s/step - loss: 0.5756 - accuracy: 0.9328 - val_loss: 0.4904 - val_accuracy: 0.9681\n"
          ]
        }
      ],
      "source": [
        "model = image_classifier.create(train_data, model_spec=model_spec.get(inception_v3_spec), validation_data=val_data,epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNXAfjl192dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee3d15e-04a9-4ff8-feab-3720aa9ffdb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2_1 (Hub  (None, 2048)             21802784  \n",
            " KerasLayerV1V2)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 10245     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,813,029\n",
            "Trainable params: 10,245\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP5FPk_tOxoZ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Evaluate "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8c2ZQ0J3Riy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f592e03b-11d4-4f5b-9ce5-4d4d962950af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 67s 7s/step - loss: 0.5027 - accuracy: 0.9681\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9O9Kx7nDQWD"
      },
      "outputs": [],
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Then plot 100 test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(20, 20))\n",
        "predicts = model.predict_top_k(test_data)\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "  predict_label = predicts[i][0][0]\n",
        "  color = get_label_color(predict_label,\n",
        "                          test_data.index_to_label[label.numpy()])\n",
        "  ax.xaxis.label.set_color(color)\n",
        "  plt.xlabel('Predicted: %s' % predict_label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im6wA9lK3TQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58049a8-25b9-4826-dae6-eea836df9edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8l3242fj/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8l3242fj/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpap0eoih9/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpap0eoih9/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
          ]
        }
      ],
      "source": [
        "model.export(export_dir='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1YoPX5wOK-u"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite('model.tflite', test_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": " Image Classification ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}